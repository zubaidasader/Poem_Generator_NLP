{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3LIFtOfnDKN"
      },
      "source": [
        "# English Poems Generator - NLP Project. \n",
        "The English Poems Generator is an NLP project that aims to generate English poems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MyCIV7o0nDKY"
      },
      "outputs": [],
      "source": [
        "# Importing needed libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Cleaning and Normalization\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dropout, Dense\n",
        "from tensorflow.keras import regularizers\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdzwFl2SnOXp",
        "outputId": "e211fd3e-39cf-41d3-a77b-ce21d3699c21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vb448CRnDKc"
      },
      "source": [
        "## Reading data\n",
        "### \"Poem Generation\" dataset \n",
        "Its collection of poems designed specifically for training and developing generative models. This dataset provides a diverse range of poems encompassing different genres, themes, and styles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nxqZTBERnDKd"
      },
      "outputs": [],
      "source": [
        "en = open('/content/drive/MyDrive/Zubaida_poem.txt', encoding=\"utf8\").read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8wy9SORnnDKe",
        "outputId": "a653059f-4718-4599-fde3-f29991f09973"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          poem\n",
              "0                 Stay, I said\n",
              "1          to the cut flowers.\n",
              "2                   They bowed\n",
              "3           their heads lower.\n",
              "4  Stay, I said to the spider,"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90a2dbd0-0cbc-4215-8fcd-cc1f014c2495\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>poem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stay, I said</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>to the cut flowers.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They bowed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>their heads lower.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stay, I said to the spider,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90a2dbd0-0cbc-4215-8fcd-cc1f014c2495')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90a2dbd0-0cbc-4215-8fcd-cc1f014c2495 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90a2dbd0-0cbc-4215-8fcd-cc1f014c2495');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Make the English poems dataset. \n",
        "poems_list = en.split(\"\\n\")\n",
        "en_df = pd.DataFrame({'poem': poems_list})\n",
        "en_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OMP2ZBsnDKg",
        "outputId": "3fd445ba-525a-4b84-acc3-aed677af1a6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2478, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "en_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpzXM2YxnDKh"
      },
      "source": [
        "## Preprocessing\n",
        "Cleaning Text: The text data is preprocessed to remove irrelevant or unnecessary elements. This involves removing stopwords using the English stopwords from the NLTK corpus, removing special characters using regular expressions, and removing punctuation marks using regular expressions.\n",
        "\n",
        "Normalizing Text: The text is further normalized to ensure consistency and ease of analysis. This includes lemmatizing the text using the WordNetLemmatizer from the NLTK library and converting the text to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB3W0vmznhOL",
        "outputId": "65d66a1c-2f14-44d6-9778-63449e1461b2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xpfhuPNvnDKi"
      },
      "outputs": [],
      "source": [
        "def remove_punctuations(text):\n",
        "    \"\"\"\n",
        "    Removes all punctuation marks from a given text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to remove punctuation from.\n",
        "\n",
        "    Returns:\n",
        "        The text with all punctuation marks removed.\n",
        "    \"\"\"\n",
        "    return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "def remove_enstopwords(text):\n",
        "    \"\"\"\n",
        "    Removes all stopwords from a given English text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to remove stopwords from.\n",
        "\n",
        "    Returns:\n",
        "        The text with all stopwords removed.\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    return \" \".join(filtered_tokens)\n",
        "\n",
        "\n",
        "def remove_special_chars(text):\n",
        "    \"\"\"\n",
        "    Removes all non-ASCII characters from a given text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to remove special characters from.\n",
        "\n",
        "    Returns:\n",
        "        The text with all non-ASCII characters removed.\n",
        "    \"\"\"\n",
        "    return re.sub(r'[^\\x00-\\x7f]', r'', text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Cu2Lm5QAnDKk"
      },
      "outputs": [],
      "source": [
        "en_df[\"cleaned_poem\"] = en_df[\"poem\"].apply(remove_enstopwords)\n",
        "en_df[\"cleaned_poem\"] = en_df[\"poem\"].apply(remove_special_chars)\n",
        "en_df[\"cleaned_poem\"] = en_df[\"poem\"].apply(remove_punctuations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-yExFJJsnDKm"
      },
      "outputs": [],
      "source": [
        "\n",
        "def standardize_text(text):    \"\"\"\n",
        "    Args:\n",
        "    text (str): The input text to be standardized.\n",
        "\n",
        "    Returns:\n",
        "        str: The standardized text.\n",
        "    \"\"\"\n",
        "    return text.lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7GxDvQlCnDKn",
        "outputId": "6272c8e2-b644-4156-89f5-e21ec7c869dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          poem               cleaned_poem  \\\n",
              "0                 Stay, I said                Stay I said   \n",
              "1          to the cut flowers.         to the cut flowers   \n",
              "2                   They bowed                 They bowed   \n",
              "3           their heads lower.          their heads lower   \n",
              "4  Stay, I said to the spider,  Stay I said to the spider   \n",
              "\n",
              "             normalized_poem  \n",
              "0                stay i said  \n",
              "1         to the cut flowers  \n",
              "2                 they bowed  \n",
              "3          their heads lower  \n",
              "4  stay i said to the spider  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a15bd75-a926-47f5-895f-a4f97c25678a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>poem</th>\n",
              "      <th>cleaned_poem</th>\n",
              "      <th>normalized_poem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stay, I said</td>\n",
              "      <td>Stay I said</td>\n",
              "      <td>stay i said</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>to the cut flowers.</td>\n",
              "      <td>to the cut flowers</td>\n",
              "      <td>to the cut flowers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They bowed</td>\n",
              "      <td>They bowed</td>\n",
              "      <td>they bowed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>their heads lower.</td>\n",
              "      <td>their heads lower</td>\n",
              "      <td>their heads lower</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stay, I said to the spider,</td>\n",
              "      <td>Stay I said to the spider</td>\n",
              "      <td>stay i said to the spider</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a15bd75-a926-47f5-895f-a4f97c25678a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a15bd75-a926-47f5-895f-a4f97c25678a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a15bd75-a926-47f5-895f-a4f97c25678a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "en_df[\"normalized_poem\"] = en_df[\"cleaned_poem\"].apply(standardize_text)\n",
        "en_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlB56lHwn9Fy",
        "outputId": "303a2d89-f4bb-4d06-d98a-52d5c4ed0431"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2478, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ATLwxKwEnDKo"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = train_test_split(en_df, test_size=0.4, shuffle=False)\n",
        "\n",
        "train_data[\"cleaned_poem\"].to_csv(\"en_train_data.txt\", index=False)\n",
        "test_data[\"cleaned_poem\"].to_csv(\"en_eval_data.txt\", index=False)\n",
        "\n",
        "en_df=train_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zkltp-6oAlP",
        "outputId": "8edb0307-afa2-4a67-fc2f-78bb5fe1a01b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1486, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScNuyhQMnDKp"
      },
      "source": [
        "## Tokenization\n",
        "The tokenization step involves breaking down the normalized text into individual tokens or words. This is achieved using the word_tokenize function from the NLTK library. The tokens are stored as a list of lists, where each sublist represents the tokenized poem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Tzsfy3aZnDKq",
        "outputId": "348a8802-6c78-43f2-fc7d-2afb854fabda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          poem               cleaned_poem  \\\n",
              "0                 Stay, I said                Stay I said   \n",
              "1          to the cut flowers.         to the cut flowers   \n",
              "2                   They bowed                 They bowed   \n",
              "3           their heads lower.          their heads lower   \n",
              "4  Stay, I said to the spider,  Stay I said to the spider   \n",
              "\n",
              "             normalized_poem                            tokens  \n",
              "0                stay i said                   [stay, i, said]  \n",
              "1         to the cut flowers           [to, the, cut, flowers]  \n",
              "2                 they bowed                     [they, bowed]  \n",
              "3          their heads lower             [their, heads, lower]  \n",
              "4  stay i said to the spider  [stay, i, said, to, the, spider]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91956b71-0770-40fb-9b96-8b4d7ca44dc8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>poem</th>\n",
              "      <th>cleaned_poem</th>\n",
              "      <th>normalized_poem</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stay, I said</td>\n",
              "      <td>Stay I said</td>\n",
              "      <td>stay i said</td>\n",
              "      <td>[stay, i, said]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>to the cut flowers.</td>\n",
              "      <td>to the cut flowers</td>\n",
              "      <td>to the cut flowers</td>\n",
              "      <td>[to, the, cut, flowers]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They bowed</td>\n",
              "      <td>They bowed</td>\n",
              "      <td>they bowed</td>\n",
              "      <td>[they, bowed]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>their heads lower.</td>\n",
              "      <td>their heads lower</td>\n",
              "      <td>their heads lower</td>\n",
              "      <td>[their, heads, lower]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stay, I said to the spider,</td>\n",
              "      <td>Stay I said to the spider</td>\n",
              "      <td>stay i said to the spider</td>\n",
              "      <td>[stay, i, said, to, the, spider]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91956b71-0770-40fb-9b96-8b4d7ca44dc8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91956b71-0770-40fb-9b96-8b4d7ca44dc8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91956b71-0770-40fb-9b96-8b4d7ca44dc8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "en_df[\"tokens\"] = en_df[\"normalized_poem\"].apply(lambda x: nltk.word_tokenize(x.lower()))\n",
        "en_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yst8je2PnDKr"
      },
      "source": [
        "## LSTM Model\n",
        "The English Poems Generator employs a deep learning model to generate poems. The model architecture consists of multiple layers, including an Embedding layer, Bidirectional LSTM layers, Dropout layers for regularization, and Dense layers for output prediction. The model is compiled with the categorical_crossentropy loss function and the Adam optimizer. Model training is performed on the predictors (input sequences) and labels (output sequences) obtained from the tokenized and padded data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rSffPTGnDKs",
        "outputId": "7ae9a7eb-bf72-44cd-9236-505f55e42502"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3108"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get the vocabulary size\n",
        "unique_words = []\n",
        "for poem in en_df[\"tokens\"]:\n",
        "    unique_words.extend(poem)\n",
        "\n",
        "vocabulary = list(set(unique_words))\n",
        "vocabulary_size = len(vocabulary)\n",
        "vocabulary_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQJF8eqvnDKt"
      },
      "outputs": [],
      "source": [
        "# Initialize the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Fit the tokenizer on your data\n",
        "tokenizer.fit_on_texts(en_df[\"tokens\"])\n",
        "\n",
        "# Save the tokenizer using pickle\n",
        "with open('en_tokenizer.pickle', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RJt4wmXnDKu"
      },
      "outputs": [],
      "source": [
        "# Converting the text into embeddings\n",
        "input_sequences = []\n",
        "for line in en_df[\"tokens\"]:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "predictors, label = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "label = tf.keras.utils.to_categorical(label, num_classes=vocabulary_size+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwSai7wCnDKu",
        "outputId": "481490ca-418b-4b51-e38b-d6ff5848dfb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 15, 100)           310900    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 15, 512)          731136    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 512)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 15, 128)           328192    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 15, 128)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1554)              101010    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3109)              4834495   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,355,141\n",
            "Trainable params: 6,355,141\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size+1, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense((vocabulary_size+1)//2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(vocabulary_size+1, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qof1WcKynDKv",
        "outputId": "adbb2d94-579c-40bd-c9f8-34389465132e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "405/405 [==============================] - 90s 191ms/step - loss: 6.8837 - accuracy: 0.0610\n",
            "Epoch 2/10\n",
            "405/405 [==============================] - 83s 205ms/step - loss: 6.4324 - accuracy: 0.0632\n",
            "Epoch 3/10\n",
            "405/405 [==============================] - 73s 180ms/step - loss: 6.3281 - accuracy: 0.0641\n",
            "Epoch 4/10\n",
            "405/405 [==============================] - 77s 191ms/step - loss: 6.2127 - accuracy: 0.0654\n",
            "Epoch 5/10\n",
            "405/405 [==============================] - 81s 199ms/step - loss: 6.1276 - accuracy: 0.0675\n",
            "Epoch 6/10\n",
            "405/405 [==============================] - 95s 236ms/step - loss: 6.0402 - accuracy: 0.0744\n",
            "Epoch 7/10\n",
            "405/405 [==============================] - 83s 206ms/step - loss: 5.9447 - accuracy: 0.0841\n",
            "Epoch 8/10\n",
            "405/405 [==============================] - 83s 204ms/step - loss: 5.8605 - accuracy: 0.0900\n",
            "Epoch 9/10\n",
            "405/405 [==============================] - 76s 188ms/step - loss: 5.7853 - accuracy: 0.0974\n",
            "Epoch 10/10\n",
            "405/405 [==============================] - 73s 181ms/step - loss: 5.7133 - accuracy: 0.1015\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(predictors, label, epochs=10, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GAx2kQ8nDKw"
      },
      "outputs": [],
      "source": [
        "model.save(\"en_poem_generation_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjpiLTBJnDKx"
      },
      "source": [
        "## Generating the poems\n",
        "To generate new poems, a seed text is provided as input. The seed text serves as the starting point for the model to generate subsequent words or tokens. Using the trained model, the generator predicts the next word based on the context and patterns learned during training. The generation process continues for a specified number of words, gradually expanding the generated poem. The temperature parameter is used to control the randomness of the generated output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTLw7QZanDKx",
        "outputId": "173ccb24-1370-4934-bdc0-f0d16d50a02a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Happiness is  the star heard a love i looked for my the white is not he a heart like happy bow this skin is know and in\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"Happiness is \"\n",
        "next_words = 25\n",
        "output_text = seed_text\n",
        "\n",
        "temperature = 0.6  # Adjust the temperature (higher values for more randomness, lower for more determinism)\n",
        "\n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "    predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "    predicted_probs = np.log(predicted_probs) / temperature\n",
        "    predicted_probs = np.exp(predicted_probs) / np.sum(np.exp(predicted_probs))\n",
        "    predicted_index = np.random.choice(len(predicted_probs), size=1, p=predicted_probs)[0]\n",
        "    output_word = tokenizer.index_word[predicted_index]\n",
        "    seed_text += \" \" + output_word\n",
        "    output_text += \" \" + output_word\n",
        "\n",
        "print(output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SDMlu1tnDKy"
      },
      "source": [
        "## GPT2 Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpt_2_simple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lGtj5n2doNNm",
        "outputId": "da79b5cd-1a60-4cff-be45-e3a1597ee6b3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gpt_2_simple\n",
            "  Downloading gpt_2_simple-0.8.1.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from gpt_2_simple) (2.12.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from gpt_2_simple) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt_2_simple) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt_2_simple) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gpt_2_simple) (1.24.3)\n",
            "Collecting toposort (from gpt_2_simple)\n",
            "  Downloading toposort-1.10-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (0.3.25)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (16.0.0)\n",
            "Collecting numpy (from gpt_2_simple)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (4.6.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (0.32.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt_2_simple) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt_2_simple) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->gpt_2_simple) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt_2_simple) (3.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.5.1->gpt_2_simple) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.5.1->gpt_2_simple) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt_2_simple) (3.2.2)\n",
            "Building wheels for collected packages: gpt_2_simple\n",
            "  Building wheel for gpt_2_simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt_2_simple: filename=gpt_2_simple-0.8.1-py3-none-any.whl size=24559 sha256=c8e7232f813b7397969028b3473d16a5fff67e65177c024333ea2de39d3dc96c\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/6a/fe/10d3223f78d1ac3e4c83bb4c5e2d28dfb1789c2fb4cc7ea8d0\n",
            "Successfully built gpt_2_simple\n",
            "Installing collected packages: toposort, numpy, gpt_2_simple\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.3\n",
            "    Uninstalling numpy-1.24.3:\n",
            "      Successfully uninstalled numpy-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.25 which is incompatible.\n",
            "flax 0.6.9 requires jax>=0.4.2, but you have jax 0.3.25 which is incompatible.\n",
            "orbax-checkpoint 0.2.1 requires jax>=0.4.8, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gpt_2_simple-0.8.1 numpy-1.23.5 toposort-1.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "L56GbRP0nDKz"
      },
      "outputs": [],
      "source": [
        "import gpt_2_simple as gpt2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpb_oF2WnDKz",
        "outputId": "3059a5bb-5d1f-450a-9aca-2dec1d5ea8c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 636Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 4.95Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 801Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:08, 59.7Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 549Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 5.70Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 5.65Mit/s]\n"
          ]
        }
      ],
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOc71Y8KnDK0"
      },
      "source": [
        "### Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "<br><br>\n",
        "Parameters:\n",
        "\n",
        "* sess: The TensorFlow session in which the fine-tuning will take place.\n",
        "\n",
        "* dataset: The name or path of the dataset file used for fine-tuning. It should be a plain text file where each training example is on a separate line.\n",
        "\n",
        "* model_name: The model architecture to use for fine-tuning. It refers to the GPT-2 model variant, such as '124M', '355M', etc. The number represents the number of parameters in millions.\n",
        "\n",
        "* steps: The number of training steps (iterations) to perform during fine-tuning.\n",
        "\n",
        "* restore_from: The checkpoint from which to restore the model weights. It can take the following values:\n",
        "    * 'fresh': Initialize the model weights randomly (starts training from scratch).\n",
        "    * 'latest': Resume training from the latest checkpoint (continues training from the last saved checkpoint).\n",
        "    * 'specific': Restore from a specific checkpoint by providing the path or name of the checkpoint file.\n",
        "* run_name: The name of the run or experiment. It is used to identify and save the checkpoints and training logs associated with this specific run.\n",
        "\n",
        "* print_every: The frequency (in steps) at which to print the training progress and loss during fine-tuning.\n",
        "\n",
        "* sample_every: The frequency (in steps) at which to generate sample outputs from the model during fine-tuning. This can be useful to monitor the model's progress and generate creative text samples.\n",
        "\n",
        "* save_every: The frequency (in steps) at which to save the model checkpoint during fine-tuning. It determines how often the model's weights and optimizer state are saved for future use or evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGVk-aVNnDK1",
        "outputId": "a674248b-267f-406c-bdb3-91921dd0ffa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1486, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yScm2h7KnDK2"
      },
      "outputs": [],
      "source": [
        "file_name = \"/content/en_train_data.txt\"\n",
        "\n",
        "sess = gpt2.start_tf_sess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYD8XRImnDK2",
        "outputId": "7ae8e5ab-d242-4a32-9a20-ca7a51d242df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7f500c166cb0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "gpt2.reset_session(sess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0yyt4vcnDK3",
        "outputId": "ef8c75c5-e74b-47bc-c76e-5ab8e9469939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 13199 tokens\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10 | 165.65] loss=3.95 avg=3.95\n",
            "Saving checkpoint/run2/model-10\n",
            "[20 | 325.61] loss=3.21 avg=3.58\n",
            "Saving checkpoint/run2/model-20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py:1067: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30 | 482.04] loss=2.40 avg=3.18\n",
            "Saving checkpoint/run2/model-30\n",
            "[40 | 632.09] loss=1.41 avg=2.73\n",
            "Saving checkpoint/run2/model-40\n",
            "[50 | 778.06] loss=0.78 avg=2.33\n",
            "Saving checkpoint/run2/model-50\n",
            "======== SAMPLE 1 ========\n",
            " my people, as the wind brings new life to your cabin\n",
            "from the sea and the mountains and other such things\n",
            "choices you make\n",
            "my women or your farm or your cabin\n",
            "choices you make\n",
            "you make\n",
            "to feed the dead and the dying\n",
            "youll find out soon enough\n",
            "when my lambs are out in the yard\n",
            "harbouring for your barn\n",
            "youll find me there\n",
            "choices you make\n",
            "to feed and clothe your flock\n",
            "and to keep the poor well off\n",
            "youll find me there\n",
            "choices you make\n",
            "to feed and clothe your family\n",
            "and to keep the poor and health conscious\n",
            "choices you make\n",
            "To feed my hungry and to clothe my child\n",
            "Ive got four small pheasants\n",
            "choices do you like very well\n",
            "To feed and clothe my baby baby\n",
            "Ive got four smart and do you like very well\n",
            "To feed and clothe my baby baby\n",
            "Ive got four pretty and do you like very well\n",
            "To feed and clothe your baby baby\n",
            "Ive got four pretty and do you like very well\n",
            "To feed and clothe your baby baby\n",
            "Dad are you able to sit down\n",
            "and have a look at the doleful\n",
            "choices are you able to sit up\n",
            "and have a look at the wall\n",
            "And to me and my little brain\n",
            "choices are you able to think\n",
            "whenever you like\n",
            "And to my brain pretty well\n",
            "Ive got one hand\n",
            "and one bit\n",
            "and the other bit\n",
            "Ive got to keep my mouth shut\n",
            "to be fair\n",
            "Ive got to hold on to as much as\n",
            "Ive got\n",
            "As much as I want\n",
            "To be able to sit down\n",
            "and have a look at the doleful\n",
            "And to me and my little brain\n",
            "And what has happened to you\n",
            "choices have you thinking\n",
            "Ive got knocked out by a hurricane\n",
            "And that was in 1803\n",
            "Ive given birth to our fourth child\n",
            "And that boy has swelled my wish\n",
            "To be able to sit down and have a look at the wall\n",
            "And to me and my little brain\n",
            "And to me and my little brain\n",
            "And to me and my little brain\n",
            "If you would have me leave\n",
            "Ive given me her wing\n",
            "And her hand is a small one\n",
            "And I will take care not to pry it open\n",
            "But if you would like me to leave\n",
            "And if possible\n",
            "To live out my honeymoon\n",
            "in plain sight\n",
            "choices do you like me to\n",
            "have to leave\n",
            "And if possible\n",
            "To live out my honeymoon\n",
            "in plain sight\n",
            "But if you would like me\n",
            "to live out my honeymoon\n",
            "in plain sight\n",
            "Then Stand by and consider\n",
            "the question\n",
            "It is a simple one but it is rather\n",
            "difficult to answer in a plain and\n",
            "veilless way\n",
            "without spoiling the point\n",
            "You see my dear young bonnie\n",
            "chochochocho and there lie\n",
            "the main points of disagreement\n",
            "the plain and the veilless\n",
            "veilless way\n",
            "Until you start to come to the very\n",
            "first doubt\n",
            "You see that question in my life\n",
            "when did I want to live and die\n",
            "and that wish that ever I\n",
            "had that I might live and die\n",
            "still haunts me today\n",
            "even though it was\n",
            "a short time ago\n",
            "when I first met my dear young bonnie\n",
            "and that wish has faded away\n",
            "but I do still have it\n",
            "choices do you like me to make\n",
            "your choice whether you like or hate me\n",
            "choices do you like me to make\n",
            "the choice between being good and being good\n",
            "like my mother who was a good\n",
            "servant and now is a sadistic torture\n",
            "chochochochocho\n",
            "And so I make the choice between being free and being free\n",
            "like my father or like my mother\n",
            "like she did a great disservice by dividing us\n",
            "and who is to say that not even me\n",
            "can be free and what good does she mean\n",
            "can I live and die on the one hand and be free on the other\n",
            "like my bonnie self who gave way to give way\n",
            "and who survives without aid or comfort\n",
            "choices do you like me to make and which are a disgrace\n",
            "to her as well as to me\n",
            "choices do you like me to make and which are a joy to be around\n",
            "and which I should shrink to another a stranger has to be\n",
            "nigerian pretty\n",
            "and I have to suffer at his feet as he is made free\n",
            "from his bondage and the lash has to be on me\n",
            "along with all the bad things he has done\n",
            "along with my bruised and weary shoulder\n",
            "A handsome bonnie but fair to be a hickory\n",
            "hickory is the bread that my mother gave me when I was a boy\n",
            "and this gave me a very special feeling\n",
            "along with all the good things that she had in store for me\n",
            "\n",
            "\n",
            "[60 | 1009.48] loss=0.26 avg=1.98\n",
            "Saving checkpoint/run2/model-60\n",
            "[70 | 1153.76] loss=0.09 avg=1.70\n",
            "Saving checkpoint/run2/model-70\n",
            "[80 | 1298.59] loss=0.08 avg=1.49\n",
            "Saving checkpoint/run2/model-80\n",
            "[90 | 1441.55] loss=0.07 avg=1.33\n",
            "Saving checkpoint/run2/model-90\n",
            "[100 | 1584.69] loss=0.05 avg=1.19\n",
            "Saving checkpoint/run2/model-100\n"
          ]
        }
      ],
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=100,\n",
        "              restore_from='fresh',\n",
        "              run_name='run2',\n",
        "              print_every=10,\n",
        "              sample_every=50,\n",
        "              save_every=10\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run2')"
      ],
      "metadata": {
        "id": "8IVrQPDyvcR_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run2')"
      ],
      "metadata": {
        "id": "l22tSwujpcmz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.load_gpt2(sess, run_name='run2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "nGyiwHEmpckW",
        "outputId": "1870b8ab-a917-4912-ccd8-f64c7a094f29"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-2c293b6e73f9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'run2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mload_gpt2\u001b[0;34m(sess, checkpoint, run_name, checkpoint_dir, model_name, model_dir, multi_gpu, reuse)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'latest'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_2_simple/src/model.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(hparams, X, past, scope, gpus, reuse)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         wpe = tf.compat.v1.get_variable('wpe', [hparams.n_ctx, hparams.n_embd],\n\u001b[0m\u001b[1;32m    189\u001b[0m                              initializer=tf.compat.v1.random_normal_initializer(stddev=0.01))\n\u001b[1;32m    190\u001b[0m         wte = tf.compat.v1.get_variable('wte', [hparams.n_vocab, hparams.n_embd],\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1615\u001b[0m                  \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariableSynchronization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m                  aggregation=VariableAggregation.NONE):\n\u001b[0;32m-> 1617\u001b[0;31m   return get_variable_scope().get_variable(\n\u001b[0m\u001b[1;32m   1618\u001b[0m       \u001b[0m_get_default_variable_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       return var_store.get_variable(\n\u001b[0m\u001b[1;32m   1328\u001b[0m           \u001b[0mfull_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    581\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m       return _true_getter(\n\u001b[0m\u001b[1;32m    584\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \"name was already created with partitioning?\" % name)\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m       return self._get_single_variable(\n\u001b[0m\u001b[1;32m    537\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;31m# ResourceVariables don't have an op associated with so no traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_variable_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;31m# Throw away internal tf entries and only take a few lines. In some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Variable model/wpe already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uQumT3snDK5"
      },
      "source": [
        "* length: The length of the generated text in terms of tokens. It determines how many tokens the generated output will contain. Note that the actual length of the output may vary depending on the model's behavior.\n",
        "\n",
        "* temperature: A parameter that controls the randomness of the generated text. Higher values (e.g., above 1.0) result in more random and diverse output, while lower values (e.g., below 1.0) make the output more focused and deterministic.\n",
        "\n",
        "* prefix: A starting prompt or seed text from which the generation begins. The generated text will continue from the given prefix.\n",
        "\n",
        "* nsamples: The number of independent samples to generate. Each sample is a separate generated output. Setting a higher value for nsamples will result in multiple generated texts.\n",
        "\n",
        "* batch_size: The number of samples to generate in parallel. Specifying a higher batch_size can improve generation speed but requires more computational resources."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = gpt2.generate(sess,\n",
        "                     length=100,\n",
        "                     run_name=\"run2\",\n",
        "                     temperature=0.7,\n",
        "                     prefix=\"Happines is\"\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARE1JHjqpciA",
        "outputId": "7aaa6247-b5fb-4a45-9fc8-c9a3bd1cba34"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Happines is a poetical bent that I can only remark\n",
            "On the flowers of the field they are as neat and they are as fair\n",
            "As the fields in the morning and they are still\n",
            "When the moons are shining bright and the dew is shining\n",
            "On the sweet tones of the sea and the land of their being\n",
            "Kissed the lilywhite and the white cot and all\n",
            "The tiniest twirl of white smoke hung over the bonnet\n",
            "Had the white foam over the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_data = pd.read_csv(\"/content/en_eval_data.txt\")\n",
        "eval_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "cCqEzhZIpccy",
        "outputId": "866f665b-c7bb-4669-8269-e3a051e17f12"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       cleaned_poem\n",
              "0               Her voice it was chanting melodious\n",
              "1                     She left me scarce able to go\n",
              "2                  My heart it is soothed in solace\n",
              "3                    My CailÃn deas crÃºite na mbÃ³\n",
              "4                    With courtesy I did salute her\n",
              "..                                              ...\n",
              "987  gunwale Islington and Isle of Wight Housewife \n",
              "988   verdict and indict Finally which rhymes with \n",
              "989       enough Though through plough or dough or \n",
              "990            cough Hiccough has the sound of cup \n",
              "991                         My advice is to give up\n",
              "\n",
              "[992 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-faa183eb-9f9e-4ab8-b7a1-e2202bdf07af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_poem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Her voice it was chanting melodious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>She left me scarce able to go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My heart it is soothed in solace</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My CailÃn deas crÃºite na mbÃ³</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>With courtesy I did salute her</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>987</th>\n",
              "      <td>gunwale Islington and Isle of Wight Housewife</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>verdict and indict Finally which rhymes with</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>enough Though through plough or dough or</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>990</th>\n",
              "      <td>cough Hiccough has the sound of cup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>My advice is to give up</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>992 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faa183eb-9f9e-4ab8-b7a1-e2202bdf07af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-faa183eb-9f9e-4ab8-b7a1-e2202bdf07af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-faa183eb-9f9e-4ab8-b7a1-e2202bdf07af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text = \"Happines is a poetical bent that I can only remark On the flowers of the field they are as neat and they are as fairAs the fields in the morning and they are still When the moons are shining bright and the dew is shining On the sweet tones of the sea and the land of their being Kissed the lilywhite and the white cot and all The tiniest twirl of white smoke hung over the bonnet Had the white foam over the\""
      ],
      "metadata": {
        "id": "zlorROPAARuu"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0e02hUspBY1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQfJ3ilYBYvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ_5qIuSnDK6"
      },
      "source": [
        "## Evaluation \n",
        "To evaluate the generated poems, a measure of perplexity is calculated. Perplexity is a common metric used to assess the quality and fluency of language models. It measures how well a model predicts the next word in a sequence. The lower the perplexity, the better the model's performance. The perplexity is calculated by comparing the predicted probabilities of the true labels in the test set and averaging the log-likelihoods. A lower perplexity indicates a higher level of coherence and fluency in the generated poems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwoTeqK3nDLN"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv(\"test_data.csv\")\n",
        "\n",
        "# Apply the same preprocessing steps as done for training data\n",
        "test_data[\"cleaned_poem\"] = test_data[\"poem\"].apply(remove_enstopwords)\n",
        "test_data[\"cleaned_poem\"] = test_data[\"poem\"].apply(remove_special_chars)\n",
        "test_data[\"cleaned_poem\"] = test_data[\"poem\"].apply(remove_punctuations)\n",
        "test_data[\"normalized_poem\"] = test_data[\"cleaned_poem\"].apply(normalize_text)\n",
        "\n",
        "# Tokenize the test data\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data[\"normalized_poem\"])\n",
        "test_sequences = pad_sequences(test_sequences, maxlen=max_sequence_len - 1, padding='pre')\n",
        "test_labels = tf.keras.utils.to_categorical(test_sequences[:, -1], num_classes=vocabulary_size+1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-jElew8nDLN",
        "outputId": "9f9e4863-ca64-4f4d-c469-f5babc9d94a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 67ms/step\n",
            "Perplexity: 8834701.0\n"
          ]
        }
      ],
      "source": [
        "# Use the model to predict probabilities for the test data\n",
        "test_predictions = model.predict(test_sequences)\n",
        "\n",
        "# Calculate the log-likelihoods of the true labels\n",
        "true_label_indices = np.argmax(test_labels, axis=1)\n",
        "log_likelihoods = np.log(test_predictions[np.arange(len(test_sequences)), true_label_indices])\n",
        "\n",
        "# Calculate perplexity\n",
        "perplexity = np.exp(-np.mean(log_likelihoods))\n",
        "print(\"Perplexity:\", perplexity)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etq4Tkw6nDLO"
      },
      "source": [
        "Some possible actions to improve the perplexity value include increasing the size and diversity of the training data, refining the model architecture, adjusting hyperparameters, or employing more advanced techniques such as transfer learning or fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEcqBz_ZnDLO"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"train_data.csv\")\n",
        "\n",
        "# Apply the same preprocessing steps as done for training data\n",
        "train_data[\"cleaned_poem\"] = train_data[\"poem\"].apply(remove_enstopwords)\n",
        "train_data[\"cleaned_poem\"] = train_data[\"poem\"].apply(remove_special_chars)\n",
        "train_data[\"cleaned_poem\"] = train_data[\"poem\"].apply(remove_punctuations)\n",
        "train_data[\"normalized_poem\"] = train_data[\"cleaned_poem\"].apply(normalize_text)\n",
        "\n",
        "# Tokenize the test data\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data[\"normalized_poem\"])\n",
        "train_sequences = pad_sequences(train_sequences, maxlen=max_sequence_len - 1, padding='pre')\n",
        "train_labels = tf.keras.utils.to_categorical(train_sequences[:, -1], num_classes=vocabulary_size+1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CphVxbanDLP"
      },
      "source": [
        "embeddings similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJaqlmC-nDLQ"
      },
      "outputs": [],
      "source": [
        "embedding_weights = model.get_layer('embedding').get_weights()[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2ZorMX7nDLQ"
      },
      "outputs": [],
      "source": [
        "generated_poems = []\n",
        "\n",
        "for poem in output_text.split(\"\\n\"):\n",
        "    generated_poem = []\n",
        "    for word in poem.split():\n",
        "        word_index = tokenizer.word_index.get(word)\n",
        "        if word_index is not None:\n",
        "            embedding_vector = embedding_weights[word_index]\n",
        "            generated_poem.append(embedding_vector)\n",
        "    generated_poems.append(generated_poem)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3PLRuXSnDLQ",
        "outputId": "332a2da9-a7e7-4b8d-fdb5-3d477034ad85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Similarity: 0.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_scores = []\n",
        "\n",
        "for generated_poem in generated_poems:\n",
        "    poem_similarity_scores = []\n",
        "    for original_poem in en_df[\"tokens\"]:\n",
        "        original_poem_embedding = []\n",
        "        for word in original_poem:\n",
        "            if word in tokenizer.word_index and tokenizer.word_index[word] in embedding_weights:\n",
        "                word_index = tokenizer.word_index[word]\n",
        "                original_poem_embedding.append(embedding_weights[word_index])\n",
        "        if len(original_poem_embedding) > 0:\n",
        "            original_poem_embedding = np.mean(original_poem_embedding, axis=0)\n",
        "            generated_poem_embedding = np.mean(generated_poem, axis=0)\n",
        "            original_poem_embedding = np.reshape(original_poem_embedding, (1, -1))\n",
        "            generated_poem_embedding = np.reshape(generated_poem_embedding, (1, -1))\n",
        "            similarity_score = cosine_similarity(original_poem_embedding, generated_poem_embedding)[0][0]\n",
        "            poem_similarity_scores.append(similarity_score)\n",
        "    if len(poem_similarity_scores) > 0:\n",
        "        similarity_scores.append(np.mean(poem_similarity_scores))\n",
        "\n",
        "if len(similarity_scores) > 0:\n",
        "    average_similarity = np.nanmean(similarity_scores)\n",
        "else:\n",
        "    average_similarity = 0.0\n",
        "\n",
        "print(\"Average Similarity:\", average_similarity)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of the GPT Model "
      ],
      "metadata": {
        "id": "phhSaViy3EbA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WIA5LaZVnDLR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kBSVbFNp3I5Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}