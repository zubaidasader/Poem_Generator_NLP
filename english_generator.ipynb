{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Poems Generator - NLP Project. \n",
    "The English Poems Generator is an NLP project that aims to generate English poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Cleaning and Normalization\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dropout, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "### \"Poem Generation\" dataset \n",
    "Its collection of poems designed specifically for training and developing generative models. This dataset provides a diverse range of poems encompassing different genres, themes, and styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = open('../PoemsNLP/en/poem.txt', encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stay, I said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to the cut flowers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They bowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>their heads lower.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stay, I said to the spider,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          poem\n",
       "0                 Stay, I said\n",
       "1          to the cut flowers.\n",
       "2                   They bowed\n",
       "3           their heads lower.\n",
       "4  Stay, I said to the spider,"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the English poems dataset. \n",
    "poems_list = en.split(\"\\n\")\n",
    "en_df = pd.DataFrame({'poem': poems_list})\n",
    "en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2478, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Cleaning Text: The text data is preprocessed to remove irrelevant or unnecessary elements. This involves removing stopwords using the English stopwords from the NLTK corpus, removing special characters using regular expressions, and removing punctuation marks using regular expressions.\n",
    "\n",
    "Normalizing Text: The text is further normalized to ensure consistency and ease of analysis. This includes lemmatizing the text using the WordNetLemmatizer from the NLTK library and converting the text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    \"\"\"\n",
    "    Removes all punctuation marks from a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to remove punctuation from.\n",
    "\n",
    "    Returns:\n",
    "        The text with all punctuation marks removed.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def remove_enstopwords(text):\n",
    "    \"\"\"\n",
    "    Removes all stopwords from a given English text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to remove stopwords from.\n",
    "\n",
    "    Returns:\n",
    "        The text with all stopwords removed.\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    \"\"\"\n",
    "    Removes all non-ASCII characters from a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to remove special characters from.\n",
    "\n",
    "    Returns:\n",
    "        The text with all non-ASCII characters removed.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^\\x00-\\x7f]', r'', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df[\"cleaned_poem\"] = en_df[\"poem\"].apply(remove_enstopwords)\n",
    "en_df[\"cleaned_poem\"] = en_df[\"poem\"].apply(remove_special_chars)\n",
    "en_df[\"cleaned_poem\"] = en_df[\"poem\"].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "    text (str): The input text to be lemmatized.\n",
    "    Returns:\n",
    "        str: The lemmatized text.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "def standardize_text(text):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    text (str): The input text to be standardized.\n",
    "\n",
    "    Returns:\n",
    "        str: The standardized text.\n",
    "    \"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalize a text by lowering the chars and lemmatizing the text. \n",
    "\n",
    "    Args:\n",
    "        text (str): The text to clean.\n",
    "\n",
    "    Returns:\n",
    "        The cleaned text.\n",
    "    \"\"\"\n",
    "    text = lemmatize_text(text)\n",
    "    text = standardize_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>cleaned_poem</th>\n",
       "      <th>normalized_poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stay, I said</td>\n",
       "      <td>Stay I said</td>\n",
       "      <td>stay i said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to the cut flowers.</td>\n",
       "      <td>to the cut flowers</td>\n",
       "      <td>to the cut flower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They bowed</td>\n",
       "      <td>They bowed</td>\n",
       "      <td>they bowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>their heads lower.</td>\n",
       "      <td>their heads lower</td>\n",
       "      <td>their head lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stay, I said to the spider,</td>\n",
       "      <td>Stay I said to the spider</td>\n",
       "      <td>stay i said to the spider</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          poem               cleaned_poem   \n",
       "0                 Stay, I said                Stay I said  \\\n",
       "1          to the cut flowers.         to the cut flowers   \n",
       "2                   They bowed                 They bowed   \n",
       "3           their heads lower.          their heads lower   \n",
       "4  Stay, I said to the spider,  Stay I said to the spider   \n",
       "\n",
       "             normalized_poem  \n",
       "0                stay i said  \n",
       "1          to the cut flower  \n",
       "2                 they bowed  \n",
       "3           their head lower  \n",
       "4  stay i said to the spider  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df[\"normalized_poem\"] = en_df[\"cleaned_poem\"].apply(normalize_text)\n",
    "en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(en_df, test_size=0.4, shuffle=False)\n",
    "\n",
    "train_data[\"cleaned_poem\"].to_csv(\"en_train_data.txt\", index=False)\n",
    "test_data[\"cleaned_poem\"].to_csv(\"en_eval_data.txt\", index=False)\n",
    "\n",
    "en_df=train_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "The tokenization step involves breaking down the normalized text into individual tokens or words. This is achieved using the word_tokenize function from the NLTK library. The tokens are stored as a list of lists, where each sublist represents the tokenized poem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>cleaned_poem</th>\n",
       "      <th>normalized_poem</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>out, joust and scour, scourging. Ear, but earn</td>\n",
       "      <td>out joust and scour scourging Ear but earn</td>\n",
       "      <td>out joust and scour scourging ear but earn</td>\n",
       "      <td>[out, joust, and, scour, scourging, ear, but, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>In Mullingar that night I rested limbs so wear...</td>\n",
       "      <td>In Mullingar that night I rested limbs so wear...</td>\n",
       "      <td>in mullingar that night i rested limb so weary...</td>\n",
       "      <td>[in, mullingar, that, night, i, rested, limb, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>(think of Psyche!) Is a paling stout and spikey?</td>\n",
       "      <td>think of Psyche Is a paling stout and spikey</td>\n",
       "      <td>think of psyche is a paling stout and spikey</td>\n",
       "      <td>[think, of, psyche, is, a, paling, stout, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>With CailÃ­n deas crÃºite na mbÃ³.</td>\n",
       "      <td>With CailÃn deas crÃºite na mbÃ³</td>\n",
       "      <td>with cailãn dea crãºite na mbã³</td>\n",
       "      <td>[with, cailãn, dea, crãºite, na, mbã³]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>Far renownd for learnin and piety;</td>\n",
       "      <td>Far renownd for learnin and piety</td>\n",
       "      <td>far renownd for learnin and piety</td>\n",
       "      <td>[far, renownd, for, learnin, and, piety]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   poem   \n",
       "2464    out, joust and scour, scourging. Ear, but earn   \\\n",
       "1561  In Mullingar that night I rested limbs so wear...   \n",
       "2469  (think of Psyche!) Is a paling stout and spikey?    \n",
       "1513                 With CailÃ­n deas crÃºite na mbÃ³.   \n",
       "1133                 Far renownd for learnin and piety;   \n",
       "\n",
       "                                           cleaned_poem   \n",
       "2464        out joust and scour scourging Ear but earn   \\\n",
       "1561  In Mullingar that night I rested limbs so wear...   \n",
       "2469      think of Psyche Is a paling stout and spikey    \n",
       "1513                   With CailÃn deas crÃºite na mbÃ³   \n",
       "1133                  Far renownd for learnin and piety   \n",
       "\n",
       "                                        normalized_poem   \n",
       "2464         out joust and scour scourging ear but earn  \\\n",
       "1561  in mullingar that night i rested limb so weary...   \n",
       "2469       think of psyche is a paling stout and spikey   \n",
       "1513                    with cailãn dea crãºite na mbã³   \n",
       "1133                  far renownd for learnin and piety   \n",
       "\n",
       "                                                 tokens  \n",
       "2464  [out, joust, and, scour, scourging, ear, but, ...  \n",
       "1561  [in, mullingar, that, night, i, rested, limb, ...  \n",
       "2469  [think, of, psyche, is, a, paling, stout, and,...  \n",
       "1513             [with, cailãn, dea, crãºite, na, mbã³]  \n",
       "1133           [far, renownd, for, learnin, and, piety]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df[\"tokens\"] = en_df[\"normalized_poem\"].apply(lambda x: nltk.word_tokenize(x.lower()))\n",
    "en_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model\n",
    "The English Poems Generator employs a deep learning model to generate poems. The model architecture consists of multiple layers, including an Embedding layer, Bidirectional LSTM layers, Dropout layers for regularization, and Dense layers for output prediction. The model is compiled with the categorical_crossentropy loss function and the Adam optimizer. Model training is performed on the predictors (input sequences) and labels (output sequences) obtained from the tokenized and padded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3108"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the vocabulary size\n",
    "unique_words = []\n",
    "for poem in en_df[\"tokens\"]:\n",
    "    unique_words.extend(poem)\n",
    "\n",
    "vocabulary = list(set(unique_words))\n",
    "vocabulary_size = len(vocabulary)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Fit the tokenizer on your data\n",
    "tokenizer.fit_on_texts(en_df[\"tokens\"])\n",
    "\n",
    "# Save the tokenizer using pickle\n",
    "with open('en_tokenizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the text into embeddings\n",
    "input_sequences = []\n",
    "for line in en_df[\"tokens\"]:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "predictors, label = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "label = tf.keras.utils.to_categorical(label, num_classes=vocabulary_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 15, 100)           310900    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 15, 512)          731136    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 512)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 15, 128)           328192    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 15, 128)           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1554)              101010    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3109)              4834495   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,355,141\n",
      "Trainable params: 6,355,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size+1, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense((vocabulary_size+1)//2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(vocabulary_size+1, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "405/405 [==============================] - 90s 191ms/step - loss: 6.8837 - accuracy: 0.0610\n",
      "Epoch 2/10\n",
      "405/405 [==============================] - 83s 205ms/step - loss: 6.4324 - accuracy: 0.0632\n",
      "Epoch 3/10\n",
      "405/405 [==============================] - 73s 180ms/step - loss: 6.3281 - accuracy: 0.0641\n",
      "Epoch 4/10\n",
      "405/405 [==============================] - 77s 191ms/step - loss: 6.2127 - accuracy: 0.0654\n",
      "Epoch 5/10\n",
      "405/405 [==============================] - 81s 199ms/step - loss: 6.1276 - accuracy: 0.0675\n",
      "Epoch 6/10\n",
      "405/405 [==============================] - 95s 236ms/step - loss: 6.0402 - accuracy: 0.0744\n",
      "Epoch 7/10\n",
      "405/405 [==============================] - 83s 206ms/step - loss: 5.9447 - accuracy: 0.0841\n",
      "Epoch 8/10\n",
      "405/405 [==============================] - 83s 204ms/step - loss: 5.8605 - accuracy: 0.0900\n",
      "Epoch 9/10\n",
      "405/405 [==============================] - 76s 188ms/step - loss: 5.7853 - accuracy: 0.0974\n",
      "Epoch 10/10\n",
      "405/405 [==============================] - 73s 181ms/step - loss: 5.7133 - accuracy: 0.1015\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(predictors, label, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"en_poem_generation_model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the poems\n",
    "To generate new poems, a seed text is provided as input. The seed text serves as the starting point for the model to generate subsequent words or tokens. Using the trained model, the generator predicts the next word based on the context and patterns learned during training. The generation process continues for a specified number of words, gradually expanding the generated poem. The temperature parameter is used to control the randomness of the generated output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happiness is  the star heard a love i looked for my the white is not he a heart like happy bow this skin is know and in\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Happiness is \"\n",
    "next_words = 25\n",
    "output_text = seed_text\n",
    "\n",
    "temperature = 0.6  # Adjust the temperature (higher values for more randomness, lower for more determinism)\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "    predicted_probs = np.log(predicted_probs) / temperature\n",
    "    predicted_probs = np.exp(predicted_probs) / np.sum(np.exp(predicted_probs))\n",
    "    predicted_index = np.random.choice(len(predicted_probs), size=1, p=predicted_probs)[0]\n",
    "    output_word = tokenizer.index_word[predicted_index]\n",
    "    seed_text += \" \" + output_word\n",
    "    output_text += \" \" + output_word\n",
    "\n",
    "print(output_text)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 95.3Mit/s]                                                     \n",
      "Fetching encoder.json: 1.05Mit [00:01, 629kit/s]                                                    \n",
      "Fetching hparams.json: 1.05Mit [00:00, 521Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [02:12, 3.76Mit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 418Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:01, 960kit/s]                                                 \n",
      "Fetching vocab.bpe: 1.05Mit [00:01, 970kit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "gpt2.download_gpt2(model_name=\"124M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune GPT-2\n",
    "\n",
    "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
    "\n",
    "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
    "\n",
    "<br><br>\n",
    "Parameters:\n",
    "\n",
    "* sess: The TensorFlow session in which the fine-tuning will take place.\n",
    "\n",
    "* dataset: The name or path of the dataset file used for fine-tuning. It should be a plain text file where each training example is on a separate line.\n",
    "\n",
    "* model_name: The model architecture to use for fine-tuning. It refers to the GPT-2 model variant, such as '124M', '355M', etc. The number represents the number of parameters in millions.\n",
    "\n",
    "* steps: The number of training steps (iterations) to perform during fine-tuning.\n",
    "\n",
    "* restore_from: The checkpoint from which to restore the model weights. It can take the following values:\n",
    "    * 'fresh': Initialize the model weights randomly (starts training from scratch).\n",
    "    * 'latest': Resume training from the latest checkpoint (continues training from the last saved checkpoint).\n",
    "    * 'specific': Restore from a specific checkpoint by providing the path or name of the checkpoint file.\n",
    "* run_name: The name of the run or experiment. It is used to identify and save the checkpoints and training logs associated with this specific run.\n",
    "\n",
    "* print_every: The frequency (in steps) at which to print the training progress and loss during fine-tuning.\n",
    "\n",
    "* sample_every: The frequency (in steps) at which to generate sample outputs from the model during fine-tuning. This can be useful to monitor the model's progress and generate creative text samples.\n",
    "\n",
    "* save_every: The frequency (in steps) at which to save the model checkpoint during fine-tuning. It determines how often the model's weights and optimizer state are saved for future use or evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(951, 3)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"en_train_data.txt\"\n",
    "\n",
    "sess = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x1bb8a1505b0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2.reset_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models\\124M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models\\124M\\model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 985.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 9136 tokens\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50 | 2176.67] loss=0.64 avg=0.64\n",
      "[100 | 4239.08] loss=0.04 avg=0.34\n",
      "[150 | 6303.85] loss=0.02 avg=0.23\n",
      "[200 | 8386.76] loss=0.02 avg=0.18\n",
      "======== SAMPLE 1 ========\n",
      " guns and arrows\n",
      "What kind of fish they had in Ukraine\n",
      "Her dad kept a pig and my wife bore\n",
      "She begged for forgiveness and promised soon she would\n",
      "The Indies and the mountains made beautiful by her soul\n",
      "Love and loathing estranged\n",
      "And where are they keeping the girls\n",
      "Because if you can be with joy\n",
      "Thou in me forever\n",
      "And with me need appear\n",
      "That the world is one\n",
      "This deep blue sky is over it all\n",
      "There were the Banns am Bastards\n",
      "The girls in their ribbons they got\n",
      "And the divil the one that did me part\n",
      "Gone a girl a judge none\n",
      "She could not be with fairer color\n",
      "White is the hairdresser's shade\n",
      "When I begged for forgiveness\n",
      "That bug my teeth were no longer sharp\n",
      "With a diamond he is a scratch\n",
      "The place where we were wed Mary I can see the traces of tears\n",
      "I love thee with a love that goes into every word\n",
      "Thou in me forever\n",
      "And I think Ill see that little stile where we sat side by side\n",
      "To where it bent in the undergrowth\n",
      "To be soon deprived a view of that fine city\n",
      "who you know\n",
      "Now most newborn babies appear in a huff\n",
      "helpmate\n",
      "And if ever I get married twill be in the month of May\n",
      "Nothing begins or ends no one loves or fights\n",
      "This saidhe wished to have me in his sight\n",
      "I flew to my pistols but alas I was mistaken\n",
      "And lovely complexions all roses and cream\n",
      "But where there is good claret plying\n",
      "That a thing a beast a man is what it is because\n",
      "My money does me no good\n",
      "With married sisters and to have the care\n",
      "And in it put Rosin the Bow\n",
      "The smug philosophers lie who say the world is one\n",
      "For ever warm and still to be enjoyd\n",
      "But satisfied I never could sleep\n",
      "And if youll but listen Ill make your eyes glisten\n",
      "All for sake of Mairi\n",
      "Asked me was I hired wages I required I was almost tired of the\n",
      "My young love said to me My mother wont mind\n",
      "And your hearts no longer mine she said\n",
      "But young Roddy McCorley goes to die on the bridge of Toome today\n",
      "For robbing Colonel Pepper on Kilgary Mountain\n",
      "Then took the other as just as fair\n",
      "Theres some takes delight in the carriages and rollin\n",
      "into your sweet mouth\n",
      "Then off to reap the corn leave where I was born\n",
      "The old ones were all dead and gone and the young ones turning grey\n",
      "As if Gods future thundered on my past\n",
      "With a load hurray  joined in the affray\n",
      "Crooning all the day long\n",
      "Where they died satisfied that their enemies they would not run from\n",
      "On the lovely sweet banks of the roses\n",
      "Oh my darling dear Ye look so queer\n",
      "Could frame thy fearful symmetry\n",
      "road and all the way to Dublin Whack fol all the Ra \n",
      "Eileen a chara I hear someone tapping\n",
      "Lazily easily now swings the wheel round\n",
      "about her childhood in a village\n",
      "And when thy heart began to beat\n",
      "That only change prevails that the seasons make the year\n",
      "If what this said I dared repeat at last\n",
      "once the traps baited with leftover pork\n",
      "And her hair hung over her shoulder\n",
      "Yell have to put with a bowl out to beg\n",
      "Sayin Oh my true love are you well\n",
      "As when she held me then\n",
      "Muses which god he shall immortalize\n",
      "into a vision of another life\n",
      "In my old griefs and with my childhoods faith\n",
      "I know not if I sink or swim\n",
      "To eat it if hes able\n",
      "She left me scarce able to go\n",
      "Old John Murray says shell die\n",
      "By a lonely prison wall\n",
      "But least is he who with enchanted eyes\n",
      "Of the love in your heart\n",
      "Each answered\n",
      "Of marble men and maidens overwrought\n",
      "They fought and they died and that was my grief said she\n",
      "The shinin golden coins did look so bright and jolly\n",
      "Though wise men at their end know dark is right\n",
      "Yes I wept for itthis    the papers light  \n",
      "Oh father dear the day will come when in answer to the call\n",
      "And your eyes twinkle bright with grief\n",
      "And to be soon deprived a look\n",
      "A rose that never would decay\n",
      "Ill think of you Molly while sun and moon shine\n",
      "I looked down the street on that very first morn\n",
      "And comrades ghosts are behind me\n",
      "And never will addle me brain\n",
      "Heres a health to you bonnie Kellswater\n",
      "They caused my heart to falter\n",
      "But not so deep as the love Im in\n",
      "Mind the latter how its written Now I surely will\n",
      "The Bann Boyne and Liffey and the Lakes of Killarney\n",
      "Her eyes they shone like the diamonds\n",
      "And the man that doesnt like me he can keep\n",
      "It will not be long love till our wedding day\n",
      "\n",
      "[250 | 10558.98] loss=0.02 avg=0.15\n",
      "[300 | 13196.05] loss=0.02 avg=0.13\n",
      "[350 | 16457.42] loss=0.02 avg=0.11\n",
      "[400 | 19378.47] loss=0.02 avg=0.10\n",
      "======== SAMPLE 1 ========\n",
      "Ove you waited\n",
      "For\n",
      "In yer wilds old laugh than fly and from whack fol any cry\n",
      "Ah the ring of the harp\n",
      "And the fire flames with a bubbling sound like a drum\n",
      "Oh the town of Kilkee and Kilrush can be seen\n",
      "My fourth green field will bloom once again said she\n",
      "Upon her shoulders fell\n",
      "And from Galway to Dublin town\n",
      "Oft in dreams I wander\n",
      "And the air will resound with hosannahs to greet you\n",
      "But destiny tore me from country and loved ones\n",
      "without moving to hide it\n",
      "It is patent to the eye that cannot face the sun\n",
      "Of Lord Lucan of old and immortal OConnell\n",
      "Boys were all merry and the girls they were hearty\n",
      "Im your captive slave for the future\n",
      "loved ones\n",
      "i thought it never would decay\n",
      "Be thou my wisdom thou my true word\n",
      "Oh the hares and lofty pheasants are plain to be seen\n",
      "Just a simple little ditty\n",
      "Close by the window young Eileen is spinning\n",
      "Or all on the African shore\n",
      "Oh to dream of it\n",
      "Some Galway boys were nigh and saw I was a hobble in\n",
      "Its entity a denial of all that is not it\n",
      "In comfort Id wish to enjoy you\n",
      "Into dancing showrs of diamond dew\n",
      "Of those that disappointment and pure spite\n",
      "It was my fortune for to meet\n",
      "The fragrance of May is soon over\n",
      "The landlord and the sheriff came to take us all away\n",
      "had to flee forever leaving all their\n",
      "I took the one less traveled by\n",
      "O see the fleetfoot host of men who march with faces drawn\n",
      "Live the Rakes of Mallow\n",
      "is the way it seems to be\n",
      "Thou shalt remain in midst of other woe\n",
      "Slowly and lowly is heard now the reels sound\n",
      "Just a simple wooden ball\n",
      "Do not go gentle into that good night\n",
      "O when I was a young man I heard my father say\n",
      "Rock of Gibraltar ringing in the background\n",
      "If I were no longer alive\n",
      "What would her lover do\n",
      "With a load hurray \n",
      "And to all the kind people Im leaving behind\n",
      "Rage rage against the dying of the light\n",
      "Oh the years of struggle and strife\n",
      "Oh the days of dreamlessness\n",
      "And what is their horror when the world turns dark\n",
      "And all the room one glow because\n",
      "The rats and the cats were a playing peek a boo\n",
      "The rats and the cats were a play on the old one\n",
      "And I soon arrived with Peggy McGilligan\n",
      "Making the house appear wider\n",
      "Could not be farther from the truth\n",
      "All Irish men of freedom stern will rally one and all\n",
      "That hed rather see me dead and buried in the clay\n",
      "And when will you return again\n",
      "O I need say\n",
      "But what are they worth in gold and silver\n",
      "Till more of the world I do see\n",
      "And I shall be all to the Lord yours\n",
      "Oh a terrible shame sink which leak out from the crevice\n",
      "All Irish men of freedom salute\n",
      "Of what use are they that would enslave and rob\n",
      "Of Irish men I have seen more bloodied than any I know\n",
      "The Gilrarlanda make Father OFlynnouse true\n",
      "The Gilgarley Ranch it is proud its worth\n",
      "To the ears of the nutbrowns childifies\n",
      "There were jovial conversations at the fair of Spadina\n",
      "of the Luphie\n",
      "The drunkenness of things being various\n",
      "Thou soul of love and bravry\n",
      "Tho all the world betrays thee\n",
      "Is what it becausay\n",
      "Tho all the world would be so unfeasull a thing\n",
      "With little bandage on them ahuggin me\n",
      "And who are you me honey\n",
      "And that has made all the difference\n",
      "What the hand dare seize the fire\n",
      "To the arms that I love best\n",
      "The coat hath many a rent this noon the sash is torn away\n",
      "Cut a stout black thorn to banish ghosts and goblins\n",
      "If my true love she were gone\n",
      "And smashed all the Chaneys at Lanigans Ball\n",
      "They put me into jail with a judge all awritin\n",
      "But let her husband be the judge of the house\n",
      "That he loves well\n",
      "And I spent all my money on whiskey and beer\n",
      "So fare you well my own true love\n",
      "In her good ould Irish way\n",
      "Oh a wan cloud was drawn oer the dim weeping dawn\n",
      "By your waters so sweet sounds the larks merry song\n",
      "Love sends his early ray\n",
      "Oer thy spirit gently stealing\n",
      "With her white spotted apron and her calico blouse\n",
      "All the young childer are wild for to play wid you\n",
      "I could not leave you with my friends for you bore your fathers name\n",
      "out joust and scour scourging Ear but earn \n",
      "Through swamps and elevations\n",
      "So why did you abandon her the reason to me tell\n",
      "Ill take you home again Kathleen\n",
      "On the hills and the glens\n",
      "\n",
      "[450 | 22177.65] loss=0.02 avg=0.09\n",
      "[500 | 25097.46] loss=0.02 avg=0.08\n",
      "Saving checkpoint\\en_run2\\model-500\n",
      "[550 | 28165.98] loss=0.01 avg=0.07\n",
      "[600 | 31292.81] loss=0.02 avg=0.07\n",
      "======== SAMPLE 1 ========\n",
      " be seen\n",
      "My mother once told me that when I was born\n",
      "Since you were first my bonnie bride\n",
      "Rage rage against the dying of the light\n",
      "Or mountainbuilt with wonderful views\n",
      "I went to her house in the middle of the night\n",
      "the endless mountains\n",
      "Well being and for what it has done\n",
      "To have fallen to my lot\n",
      "That too your very pure heart\n",
      "I can see the tears begin to drain\n",
      "From the shore\n",
      "Atoll of the morn\n",
      "He can beg for his dinner he has nothing else to do\n",
      "I heard a siren from the docks\n",
      "gunwale Islington and Isle of Wight Housewife \n",
      "Up the narrow street he stepped so smiling proud and young\n",
      "Ive only this one consolation\n",
      "All your foes are friends and all your days are nights\n",
      "by lifes betrayals\n",
      "Such a custom as yours I could have any day\n",
      "If you give me your hand\n",
      "What immortal hand or eye\n",
      "Action along with error growth along with gaps\n",
      "slipped into my attic room\n",
      "And tomorrow she shall hear\n",
      "Stay to the earth\n",
      "And Ill ask them to pardon their prodigal son\n",
      "I was once young and pretty and my spirit ran free\n",
      "One brave English captain was ranting that day\n",
      "Heart of my own heart whatever befall\n",
      "The red blaze of freedom in Erin Go Bragh\n",
      "Flowing through heather limpid brown\n",
      "The name of old Rosin the Bow\n",
      "Did I meet with in shawl or gown\n",
      "She threw her arms around me saying Johnny I love you still\n",
      "With CailÃn deas crÃºite na mbÃ³\n",
      "Then came a lusty sailor\n",
      "and escape\n",
      "Now a prison ship lies waiting in the bay\n",
      "Live the Rakes of Mallow\n",
      "disciple label Petal panel and canal Wait \n",
      "staring at the moment when\n",
      "In a gesture of peace\n",
      "My four green fields ran red with their blood said she\n",
      "Saying Theres plenty of oats for a soldiers horse\n",
      "Can only live by strife in that the living die\n",
      "All from the island of Sulloon\n",
      "And what shoulder and what art\n",
      "Oh Haste to the Wedding the pipes the pipes are calling\n",
      "Youre landed in Van Diemans Land\n",
      "Time was away and somewhere else\n",
      "Tabhair dom do lÃmh\n",
      "But her ghost wheels her barrow\n",
      "Something crossed me mind when I looked behind\n",
      "For Australia bound if we didnt all drown\n",
      "Far away from my friends and relations\n",
      "if you can live with failure\n",
      "O Paddy dear and did ye hear the news thats goin round\n",
      "When at home with dada dying\n",
      "There was war and death plundering and pillage\n",
      "Who was selling her trade in the bar\n",
      "Gad youve your flock in the grandest control\n",
      "Mellow the moonlight to shine is beginning\n",
      "From glen to glen and down the mountain side\n",
      "Between that meaning and the matter it should fill\n",
      "And its no nay never\n",
      "Plenty peat to fill her creel\n",
      "Julia and I we banished their nonsense\n",
      "Thou my great Father I thy true Son\n",
      "Tiger Tiger burning bright\n",
      "Your heart was ever fond and true\n",
      "Oh do not to my flame add fuel\n",
      "If man is a mere mirror of God the gods collapse\n",
      "Oh Bridgit OMalley youve left my heart shaken\n",
      "So I went to her house in the middle of the night\n",
      "the endless mountains\n",
      "Well if youll believe me when asked to a ball\n",
      "For he tore its chords asunder\n",
      "When the green flag went up and the Crown rag came down\n",
      "of a grownups\n",
      "Incorrigibly plural I peel and portion\n",
      "At noon it must fall to low rate\n",
      "one long and detailed\n",
      "When I met with a pretty young damsel\n",
      "My aged father stood at the door\n",
      "from the inside\n",
      "Cannot the clergy be Irishmen too\n",
      "Puts her foot on the stool spins the wheel with the other\n",
      "I slept in a barn one night in Currabawn\n",
      "it died The blue light\n",
      "And when I tell Frances I see she is a moon\n",
      "With beautiful shapes nature never designed\n",
      "There were the Nolans Dolans OGradys\n",
      "Soft is the grass my bed is free\n",
      "For thyme it is a precious thing\n",
      "When you and I will be as one\n",
      "To that cot again\n",
      "Where the green was last seen by proud Saxon and Tory\n",
      "The drunkenness of things being various\n",
      "Thou soul of love and bravry\n",
      "Tho all the world betrays thee\n",
      "Did he smile his work to see\n",
      "and still stand at the edge of the lake\n",
      "Holding its inverted poise\n",
      "Beloved my Beloved when I think \n",
      "Is more spiteful and gay than one supposes \n",
      "The harp that once sounded in Taras old hall\n",
      "And one by one the merry hearts are fled\n",
      "Gone alas like our youth too soon\n",
      "And you good people that do pass by\n",
      "moreover Between m\n",
      "\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\xc3' in position 1362: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m sess \u001b[39m=\u001b[39m gpt2\u001b[39m.\u001b[39mstart_tf_sess()\n\u001b[1;32m----> 3\u001b[0m gpt2\u001b[39m.\u001b[39;49mfinetune(sess,\n\u001b[0;32m      4\u001b[0m               dataset\u001b[39m=\u001b[39;49mfile_name,\n\u001b[0;32m      5\u001b[0m               model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m124M\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m               steps\u001b[39m=\u001b[39;49m\u001b[39m2000\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m               restore_from\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfresh\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m               run_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39men_run2\u001b[39;49m\u001b[39m'\u001b[39;49m,  \n\u001b[0;32m      9\u001b[0m               print_every\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m     10\u001b[0m               sample_every\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[0;32m     11\u001b[0m               save_every\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m\n\u001b[0;32m     12\u001b[0m              )\n",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\gpt_2.py:334\u001b[0m, in \u001b[0;36mfinetune\u001b[1;34m(sess, dataset, steps, model_name, model_dir, combine, batch_size, learning_rate, accumulate_gradients, restore_from, run_name, checkpoint_dir, sample_every, sample_length, sample_num, multi_gpu, save_every, print_every, max_checkpoints, use_memory_saving_gradients, only_train_transformer_layers, optimizer, overwrite, reuse)\u001b[0m\n\u001b[0;32m    332\u001b[0m     save()\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m (counter \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m sample_every \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m counter \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 334\u001b[0m     generate_samples()\n\u001b[0;32m    336\u001b[0m \u001b[39mif\u001b[39;00m accumulate_gradients \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    337\u001b[0m     sess\u001b[39m.\u001b[39mrun(opt_reset)\n",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\gpt_2.py:309\u001b[0m, in \u001b[0;36mfinetune.<locals>.generate_samples\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m maketree(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(SAMPLE_DIR, run_name))\n\u001b[0;32m    306\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    307\u001b[0m         os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(SAMPLE_DIR, run_name,\n\u001b[0;32m    308\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39msamples-\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mformat(counter), \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fp:\n\u001b[1;32m--> 309\u001b[0m     fp\u001b[39m.\u001b[39;49mwrite(\u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(all_text))\n",
      "File \u001b[1;32mC:\\Python310\\lib\\encodings\\cp1256.py:19\u001b[0m, in \u001b[0;36mIncrementalEncoder.encode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39;49mcharmap_encode(\u001b[39minput\u001b[39;49m,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,encoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\xc3' in position 1362: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name='124M',\n",
    "              steps=2000,\n",
    "              restore_from='fresh',\n",
    "              run_name='en_run2',  \n",
    "              print_every=50,\n",
    "              sample_every=200,\n",
    "              save_every=500\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x1bb6a4e6650>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2.reset_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't load save_path when it is None.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m sess \u001b[39m=\u001b[39m gpt2\u001b[39m.\u001b[39mstart_tf_sess()\n\u001b[1;32m----> 3\u001b[0m gpt2\u001b[39m.\u001b[39;49mfinetune(sess,\n\u001b[0;32m      4\u001b[0m               dataset\u001b[39m=\u001b[39;49mfile_name,\n\u001b[0;32m      5\u001b[0m               model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m124M\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m               steps\u001b[39m=\u001b[39;49m\u001b[39m2000\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m               restore_from\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcheckpoint/en_run2/model-161\u001b[39;49m\u001b[39m'\u001b[39;49m,  \u001b[39m# Path to the checkpoint\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m               run_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39men_run2\u001b[39;49m\u001b[39m'\u001b[39;49m,  \n\u001b[0;32m      9\u001b[0m               print_every\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m     10\u001b[0m               sample_every\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[0;32m     11\u001b[0m               save_every\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m\n\u001b[0;32m     12\u001b[0m              )\n",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\gpt_2.py:260\u001b[0m, in \u001b[0;36mfinetune\u001b[1;34m(sess, dataset, steps, model_name, model_dir, combine, batch_size, learning_rate, accumulate_gradients, restore_from, run_name, checkpoint_dir, sample_every, sample_length, sample_num, multi_gpu, save_every, print_every, max_checkpoints, use_memory_saving_gradients, only_train_transformer_layers, optimizer, overwrite, reuse)\u001b[0m\n\u001b[0;32m    258\u001b[0m     ckpt \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mlatest_checkpoint(restore_from)\n\u001b[0;32m    259\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoading checkpoint\u001b[39m\u001b[39m'\u001b[39m, ckpt)\n\u001b[1;32m--> 260\u001b[0m saver\u001b[39m.\u001b[39;49mrestore(sess, ckpt)\n\u001b[0;32m    262\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoading dataset...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    263\u001b[0m chunks \u001b[39m=\u001b[39m load_dataset(enc, dataset, combine)\n",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1406\u001b[0m, in \u001b[0;36mSaver.restore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1404\u001b[0m   \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m \u001b[39mif\u001b[39;00m save_path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1406\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load save_path when it is None.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1408\u001b[0m checkpoint_prefix \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_text(save_path)\n\u001b[0;32m   1409\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m checkpoint_management\u001b[39m.\u001b[39mcheckpoint_exists_internal(checkpoint_prefix):\n",
      "\u001b[1;31mValueError\u001b[0m: Can't load save_path when it is None."
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name='124M',\n",
    "              steps=2000,\n",
    "              restore_from='checkpoint/en_run2/model-161',  # Path to the checkpoint\n",
    "              run_name='en_run2',  \n",
    "              print_every=50,\n",
    "              sample_every=200,\n",
    "              save_every=500\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'gpt_2_simple' has no attribute 'save_checkpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gpt2\u001b[39m.\u001b[39;49msave_checkpoint(run_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39men_run2\u001b[39m\u001b[39m'\u001b[39m, checkpoint_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../poemsNLP\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'gpt_2_simple' has no attribute 'save_checkpoint'"
     ]
    }
   ],
   "source": [
    "gpt2.save_checkpoint(run_name='en_run2', checkpoint_dir='../poemsNLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node 'sample_sequence_2/model/h10/ln_2/add_1/ReadVariableOp' defined at (most recent call last):\n    File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_344\\4165053288.py\", line 1, in <module>\n      gpt2.generate(sess, run_name='en_run2')\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\gpt_2.py\", line 462, in generate\n      output = sample.sample_sequence(\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\sample.py\", line 67, in sample_sequence\n      context_output = step(hparams, context[:, :-1])\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\sample.py\", line 51, in step\n      lm_output = model.model(hparams=hparams, X=tokens,\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\model.py\", line 203, in model\n      h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\model.py\", line 158, in block\n      m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\model.py\", line 67, in norm\n      x = x*g + b\nNode: 'sample_sequence_2/model/h10/ln_2/add_1/ReadVariableOp'\nCould not find variable model/h10/ln_2/b. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Container localhost does not exist. (Could not find resource: localhost/model/h10/ln_2/b)\n\t [[{{node sample_sequence_2/model/h10/ln_2/add_1/ReadVariableOp}}]]\n\nOriginal stack trace for 'sample_sequence_2/model/h10/ln_2/add_1/ReadVariableOp':\n  File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n    app.start()\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n    self.io_loop.start()\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n    self._run_once()\n  File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n    handle._run()\n  File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n    await self.process_one()\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n    await dispatch(*args)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n    await result\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n    reply_content = await reply_content\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n    res = shell.run_cell(\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n    result = self._run_cell(\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n    result = runner(coro)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_344\\4165053288.py\", line 1, in <module>\n    gpt2.generate(sess, run_name='en_run2')\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\gpt_2.py\", line 462, in generate\n    output = sample.sample_sequence(\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\sample.py\", line 67, in sample_sequence\n    context_output = step(hparams, context[:, :-1])\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\sample.py\", line 51, in step\n    lm_output = model.model(hparams=hparams, X=tokens,\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\model.py\", line 203, in model\n    h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\model.py\", line 158, in block\n    m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\model.py\", line 67, in norm\n    x = x*g + b\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1459, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1176, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1805, in _add_dispatch\n    y = ops.convert_to_tensor(y, dtype_hint=x.dtype.base_dtype, name=\"y\")\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in convert_to_tensor\n    ret = conversion_func(\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 2274, in _dense_var_to_tensor\n    return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)  # pylint: disable=protected-access\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 1516, in _dense_var_to_tensor\n    return self.value()\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 592, in value\n    return self._read_variable_op()\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 753, in _read_variable_op\n    result = read_and_set_handle(no_copy)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 743, in read_and_set_handle\n    result = gen_resource_variable_ops.read_variable_op(\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\", line 594, in read_variable_op\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1379\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1361\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1362\u001b[0m                                 target_list, run_metadata)\n",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1453\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1454\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[0;32m   1455\u001b[0m                                           fetch_list, target_list,\n\u001b[0;32m   1456\u001b[0m                                           run_metadata)\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Could not find variable model/h10/ln_2/b. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Container localhost does not exist. (Could not find resource: localhost/model/h10/ln_2/b)\n\t [[{{node sample_sequence_2/model/h10/ln_2/add_1/ReadVariableOp}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gpt2\u001b[39m.\u001b[39;49mgenerate(sess, run_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39men_run2\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\gpt_2.py:477\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(sess, run_name, checkpoint_dir, model_name, model_dir, sample_dir, return_as_list, truncate, destination_path, sample_delim, prefix, seed, nsamples, batch_size, length, temperature, top_k, top_p, include_prefix)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[39mwhile\u001b[39;00m generated \u001b[39m<\u001b[39m nsamples:\n\u001b[0;32m    476\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m prefix:\n\u001b[1;32m--> 477\u001b[0m         out \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39;49mrun(output)\n\u001b[0;32m    478\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    479\u001b[0m         out \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39mrun(output, feed_dict\u001b[39m=\u001b[39m{\n\u001b[0;32m    480\u001b[0m                 context: batch_size \u001b[39m*\u001b[39m [context_tokens]\n\u001b[0;32m    481\u001b[0m             })\n",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    969\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    970\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1191\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[0;32m   1192\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m   1372\u001b[0m                        run_metadata)\n\u001b[0;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1397\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39monly supports NHWC tensor format\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m message:\n\u001b[0;32m   1393\u001b[0m   message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1394\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mby modifying the config for creating the session eg.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1395\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39msession_config.graph_options.rewrite_options.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1396\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mdisable_meta_optimizer = True\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1397\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nDetected at node 'sample_sequence_2/model/h10/ln_2/add_1/ReadVariableOp' defined at (most recent call last):\n    File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_344\\4165053288.py\", line 1, in <module>\n      gpt2.generate(sess, run_name='en_run2')\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\gpt_2.py\", line 462, in generate\n      output = sample.sample_sequence(\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\sample.py\", line 67, in sample_sequence\n      context_output = step(hparams, context[:, :-1])\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\sample.py\", line 51, in step\n      lm_output = model.model(hparams=hparams, X=tokens,\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\model.py\", line 203, in model\n      h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\model.py\", line 158, in block\n      m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n    File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\model.py\", line 67, in norm\n      x = x*g + b\nNode: 'sample_sequence_2/model/h10/ln_2/add_1/ReadVariableOp'\nCould not find variable model/h10/ln_2/b. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Container localhost does not exist. (Could not find resource: localhost/model/h10/ln_2/b)\n\t [[{{node sample_sequence_2/model/h10/ln_2/add_1/ReadVariableOp}}]]\n\nOriginal stack trace for 'sample_sequence_2/model/h10/ln_2/add_1/ReadVariableOp':\n  File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n    app.start()\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n    self.io_loop.start()\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n    self._run_once()\n  File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n    handle._run()\n  File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n    await self.process_one()\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n    await dispatch(*args)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n    await result\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n    reply_content = await reply_content\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n    res = shell.run_cell(\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n    result = self._run_cell(\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n    result = runner(coro)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_344\\4165053288.py\", line 1, in <module>\n    gpt2.generate(sess, run_name='en_run2')\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\gpt_2.py\", line 462, in generate\n    output = sample.sample_sequence(\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\sample.py\", line 67, in sample_sequence\n    context_output = step(hparams, context[:, :-1])\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\sample.py\", line 51, in step\n    lm_output = model.model(hparams=hparams, X=tokens,\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\model.py\", line 203, in model\n    h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\model.py\", line 158, in block\n    m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\src\\model.py\", line 67, in norm\n    x = x*g + b\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1459, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1176, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1805, in _add_dispatch\n    y = ops.convert_to_tensor(y, dtype_hint=x.dtype.base_dtype, name=\"y\")\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in convert_to_tensor\n    ret = conversion_func(\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 2274, in _dense_var_to_tensor\n    return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)  # pylint: disable=protected-access\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 1516, in _dense_var_to_tensor\n    return self.value()\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 592, in value\n    return self._read_variable_op()\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 753, in _read_variable_op\n    result = read_and_set_handle(no_copy)\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 743, in read_and_set_handle\n    result = gen_resource_variable_ops.read_variable_op(\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\", line 594, in read_variable_op\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"c:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess, run_name='en_run2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* length: The length of the generated text in terms of tokens. It determines how many tokens the generated output will contain. Note that the actual length of the output may vary depending on the model's behavior.\n",
    "\n",
    "* temperature: A parameter that controls the randomness of the generated text. Higher values (e.g., above 1.0) result in more random and diverse output, while lower values (e.g., below 1.0) make the output more focused and deterministic.\n",
    "\n",
    "* prefix: A starting prompt or seed text from which the generation begins. The generated text will continue from the given prefix.\n",
    "\n",
    "* nsamples: The number of independent samples to generate. Each sample is a separate generated output. Setting a higher value for nsamples will result in multiple generated texts.\n",
    "\n",
    "* batch_size: The number of samples to generate in parallel. Specifying a higher batch_size can improve generation speed but requires more computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text \u001b[39m=\u001b[39m gpt2\u001b[39m.\u001b[39;49mgenerate(sess,\n\u001b[0;32m      2\u001b[0m               length\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[0;32m      3\u001b[0m               temperature\u001b[39m=\u001b[39;49m\u001b[39m0.7\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m               prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mStay\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m               nsamples\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m               batch_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m               )\n",
      "File \u001b[1;32mc:\\Users\\User\\PoemsNLP\\poems\\lib\\site-packages\\gpt_2_simple\\gpt_2.py:437\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(sess, run_name, checkpoint_dir, model_name, model_dir, sample_dir, return_as_list, truncate, destination_path, sample_delim, prefix, seed, nsamples, batch_size, length, temperature, top_k, top_p, include_prefix)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[39mif\u001b[39;00m batch_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 437\u001b[0m \u001b[39massert\u001b[39;00m nsamples \u001b[39m%\u001b[39m batch_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m nsamples \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    440\u001b[0m     sample_delim \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = gpt2.generate(sess,\n",
    "              length=100,\n",
    "              temperature=0.7,\n",
    "              prefix=\"Stay\",\n",
    "              nsamples=2,\n",
    "              batch_size=3,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "To evaluate the generated poems, a measure of perplexity is calculated. Perplexity is a common metric used to assess the quality and fluency of language models. It measures how well a model predicts the next word in a sequence. The lower the perplexity, the better the model's performance. The perplexity is calculated by comparing the predicted probabilities of the true labels in the test set and averaging the log-likelihoods. A lower perplexity indicates a higher level of coherence and fluency in the generated poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "# Apply the same preprocessing steps as done for training data\n",
    "test_data[\"cleaned_poem\"] = test_data[\"poem\"].apply(remove_enstopwords)\n",
    "test_data[\"cleaned_poem\"] = test_data[\"poem\"].apply(remove_special_chars)\n",
    "test_data[\"cleaned_poem\"] = test_data[\"poem\"].apply(remove_punctuations)\n",
    "test_data[\"normalized_poem\"] = test_data[\"cleaned_poem\"].apply(normalize_text)\n",
    "\n",
    "# Tokenize the test data\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data[\"normalized_poem\"])\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_sequence_len - 1, padding='pre')\n",
    "test_labels = tf.keras.utils.to_categorical(test_sequences[:, -1], num_classes=vocabulary_size+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 67ms/step\n",
      "Perplexity: 8834701.0\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict probabilities for the test data\n",
    "test_predictions = model.predict(test_sequences)\n",
    "\n",
    "# Calculate the log-likelihoods of the true labels\n",
    "true_label_indices = np.argmax(test_labels, axis=1)\n",
    "log_likelihoods = np.log(test_predictions[np.arange(len(test_sequences)), true_label_indices])\n",
    "\n",
    "# Calculate perplexity\n",
    "perplexity = np.exp(-np.mean(log_likelihoods))\n",
    "print(\"Perplexity:\", perplexity)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some possible actions to improve the perplexity value include increasing the size and diversity of the training data, refining the model architecture, adjusting hyperparameters, or employing more advanced techniques such as transfer learning or fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "\n",
    "# Apply the same preprocessing steps as done for training data\n",
    "train_data[\"cleaned_poem\"] = train_data[\"poem\"].apply(remove_enstopwords)\n",
    "train_data[\"cleaned_poem\"] = train_data[\"poem\"].apply(remove_special_chars)\n",
    "train_data[\"cleaned_poem\"] = train_data[\"poem\"].apply(remove_punctuations)\n",
    "train_data[\"normalized_poem\"] = train_data[\"cleaned_poem\"].apply(normalize_text)\n",
    "\n",
    "# Tokenize the test data\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data[\"normalized_poem\"])\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_sequence_len - 1, padding='pre')\n",
    "train_labels = tf.keras.utils.to_categorical(train_sequences[:, -1], num_classes=vocabulary_size+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embeddings similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = model.get_layer('embedding').get_weights()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_poems = []\n",
    "\n",
    "for poem in output_text.split(\"\\n\"):\n",
    "    generated_poem = []\n",
    "    for word in poem.split():\n",
    "        word_index = tokenizer.word_index.get(word)\n",
    "        if word_index is not None:\n",
    "            embedding_vector = embedding_weights[word_index]\n",
    "            generated_poem.append(embedding_vector)\n",
    "    generated_poems.append(generated_poem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Similarity: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_scores = []\n",
    "\n",
    "for generated_poem in generated_poems:\n",
    "    poem_similarity_scores = []\n",
    "    for original_poem in en_df[\"tokens\"]:\n",
    "        original_poem_embedding = []\n",
    "        for word in original_poem:\n",
    "            if word in tokenizer.word_index and tokenizer.word_index[word] in embedding_weights:\n",
    "                word_index = tokenizer.word_index[word]\n",
    "                original_poem_embedding.append(embedding_weights[word_index])\n",
    "        if len(original_poem_embedding) > 0:\n",
    "            original_poem_embedding = np.mean(original_poem_embedding, axis=0)\n",
    "            generated_poem_embedding = np.mean(generated_poem, axis=0)\n",
    "            original_poem_embedding = np.reshape(original_poem_embedding, (1, -1))\n",
    "            generated_poem_embedding = np.reshape(generated_poem_embedding, (1, -1))\n",
    "            similarity_score = cosine_similarity(original_poem_embedding, generated_poem_embedding)[0][0]\n",
    "            poem_similarity_scores.append(similarity_score)\n",
    "    if len(poem_similarity_scores) > 0:\n",
    "        similarity_scores.append(np.mean(poem_similarity_scores))\n",
    "\n",
    "if len(similarity_scores) > 0:\n",
    "    average_similarity = np.nanmean(similarity_scores)\n",
    "else:\n",
    "    average_similarity = 0.0\n",
    "\n",
    "print(\"Average Similarity:\", average_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
